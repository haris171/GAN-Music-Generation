{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "from music21 import converter, instrument, note, chord\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMGenerator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(LSTMGenerator, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h0 = torch.zeros(2, batch_size, self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(2, batch_size, self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x.unsqueeze(1), (h0.squeeze(0), c0.squeeze(0)))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "class LSTMDiscriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTMDiscriminator, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h0 = torch.zeros(2, batch_size, self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(2, batch_size, self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x.unsqueeze(1), (h0.squeeze(0), c0.squeeze(0)))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "class MusicLoader:\n",
    "    def __init__(self, folder_path: str):\n",
    "        self.folder_path = folder_path\n",
    "\n",
    "    def load_data(self) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        notes = []\n",
    "        durations = []\n",
    "        offsets = []\n",
    "\n",
    "        for file in glob.glob(self.folder_path + \"/*.mid\"):\n",
    "            try:\n",
    "                midi = converter.parse(file)\n",
    "                print(\"Parsing %s\" % file)\n",
    "\n",
    "                notes_to_parse = None\n",
    "\n",
    "                try: # file has instrument parts\n",
    "                    s2 = instrument.partitionByInstrument(midi)\n",
    "                    notes_to_parse = s2.parts[0].recurse()\n",
    "                except: # file has notes in a flat structure\n",
    "                    notes_to_parse = midi.flat.notes\n",
    "\n",
    "                offset_base = 0\n",
    "                for element in notes_to_parse:\n",
    "                    is_note_or_chord = False\n",
    "\n",
    "                    if isinstance(element, note.Note):\n",
    "                        pitch_number = element.pitch.midi\n",
    "                        notes.append(pitch_number)\n",
    "                        is_note_or_chord = True\n",
    "                    elif isinstance(element, chord.Chord):\n",
    "                        pitches = [n.pitch.midi for n in element.normalOrder]\n",
    "                        notes.append(pitches)\n",
    "                        is_note_or_chord = True\n",
    "\n",
    "                    if is_note_or_chord:\n",
    "                        offsets.append(element.offset - offset_base)\n",
    "                        durations.append(element.quarterLength)\n",
    "                        is_note_or_chord = False\n",
    "                        offset_base = element.offset\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing file {file}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Convert lists to PyTorch tensors\n",
    "        notes_tensor = torch.tensor(notes, dtype=torch.float)\n",
    "        durations_tensor = torch.tensor(durations, dtype=torch.float)\n",
    "        offsets_tensor = torch.tensor(offsets, dtype=torch.float)\n",
    "\n",
    "        return notes_tensor, durations_tensor, offsets_tensor\n",
    "\n",
    "\n",
    "class MIDIDataset(Dataset):\n",
    "    def __init__(self, notes, durations, offsets):\n",
    "        self.notes = torch.tensor(notes, dtype=torch.float)\n",
    "        self.durations = torch.tensor(durations, dtype=torch.float)\n",
    "        self.offsets = torch.tensor(offsets, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.notes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.notes[idx], self.durations[idx], self.offsets[idx]\n",
    "\n",
    "\n",
    "def train_network(generator, discriminator, train_loader, num_epochs, lr_gen, lr_disc, device):\n",
    "    generator.to(device)\n",
    "    discriminator.to(device)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer_gen = optim.Adam(generator.parameters(), lr=lr_gen)\n",
    "    optimizer_disc = optim.Adam(discriminator.parameters(), lr=lr_disc)\n",
    "\n",
    "    best_gen_loss = float('inf')\n",
    "    best_disc_loss = float('inf')\n",
    "    best_gen_state = None\n",
    "    best_disc_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (notes, durations, offsets) in enumerate(train_loader):\n",
    "            notes, durations, offsets = notes.to(device), durations.to(device), offsets.to(device)\n",
    "\n",
    "            # Train Discriminator\n",
    "            optimizer_disc.zero_grad()\n",
    "            \n",
    "            # Concatenate notes, durations, and offsets along the second dimension\n",
    "            real_samples = torch.cat((notes.unsqueeze(1),\n",
    "                                      durations.unsqueeze(1),\n",
    "                                      offsets.unsqueeze(1)), dim=1)\n",
    "\n",
    "            batch_size = real_samples.size(0)\n",
    "            h0 = torch.zeros(2, batch_size, discriminator.hidden_size).to(device)\n",
    "            c0 = torch.zeros(2, batch_size, discriminator.hidden_size).to(device)\n",
    "            real_outputs = discriminator(real_samples)\n",
    "            \n",
    "            # Generate fake samples\n",
    "            fake_samples = generator(torch.randn(batch_size, 100).to(device))\n",
    "            fake_outputs = discriminator(fake_samples)\n",
    "\n",
    "            real_labels = torch.ones((batch_size, 1)).to(device)\n",
    "            fake_labels = torch.zeros((batch_size, 1)).to(device)\n",
    "\n",
    "            disc_loss_real = criterion(real_outputs, real_labels)\n",
    "            disc_loss_fake = criterion(fake_outputs, fake_labels)\n",
    "            disc_loss = disc_loss_real + disc_loss_fake\n",
    "            disc_loss.backward()\n",
    "            optimizer_disc.step()\n",
    "\n",
    "            # Train Generator\n",
    "            optimizer_gen.zero_grad()\n",
    "            fake_samples = generator(torch.randn(batch_size, 100).to(device))\n",
    "            fake_outputs = discriminator(fake_samples)\n",
    "            gen_loss = criterion(fake_outputs, real_labels)\n",
    "            gen_loss.backward()\n",
    "            optimizer_gen.step()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Discriminator Loss: {disc_loss.item():.4f}, Generator Loss: {gen_loss.item():.4f}')\n",
    "        \n",
    "        # Update best model states and losses\n",
    "        if gen_loss < best_gen_loss:\n",
    "            best_gen_loss = gen_loss\n",
    "            best_gen_state = generator.state_dict()\n",
    "        if disc_loss < best_disc_loss:\n",
    "            best_disc_loss = disc_loss\n",
    "            best_disc_state = discriminator.state_dict()\n",
    "    \n",
    "    return best_gen_state, best_disc_state, best_gen_loss.item(), best_disc_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing Music/haydn_43_1.mid\n",
      "Parsing Music/ty_august.mid\n",
      "Parsing Music/muss_2.mid\n",
      "Parsing Music/rav_gib.mid\n",
      "Parsing Music/waldstein_1.mid\n",
      "Parsing Music/schumm-1.mid\n",
      "Parsing Music/chpn_op23.mid\n",
      "Parsing Music/chpn-p19.mid\n",
      "Parsing Music/chpn_op7_2.mid\n",
      "Parsing Music/beethoven_opus90_2.mid\n",
      "Parsing Music/chpn-p18.mid\n",
      "Parsing Music/chpn-p24.mid\n",
      "Parsing Music/mendel_op19_1.mid\n",
      "Parsing Music/grieg_kobold.mid\n",
      "Parsing Music/muss_3.mid\n",
      "Parsing Music/haydn_43_2.mid\n",
      "Parsing Music/muss_1.mid\n",
      "Parsing Music/burg_sylphen.mid\n",
      "Parsing Music/waldstein_2.mid\n",
      "Parsing Music/schumm-2.mid\n",
      "Parsing Music/burg_quelle.mid\n",
      "Parsing Music/mendel_op19_3.mid\n",
      "Parsing Music/schub_d960_4.mid\n",
      "Parsing Music/chpn_op7_1.mid\n",
      "Parsing Music/schum_abegg.mid\n",
      "Parsing Music/gra_esp_4.mid\n",
      "Parsing Music/islamei.mid\n",
      "Parsing Music/beethoven_opus90_1.mid\n",
      "Error parsing file Music/mendel_op19_2.mid: 5142116432\n",
      "Parsing Music/schumm-3.mid\n",
      "Parsing Music/waldstein_3.mid\n",
      "Error parsing file Music/waldstein_3.mid: 'int' object has no attribute 'pitch'\n",
      "Parsing Music/haydn_8_4.mid\n",
      "Parsing Music/haydn_43_3.mid\n",
      "Parsing Music/rac_op33_8.mid\n",
      "Parsing Music/muss_4.mid\n",
      "Parsing Music/bach_847.mid\n",
      "Parsing Music/scn68_10.mid\n",
      "Parsing Music/ty_dezember.mid\n",
      "Parsing Music/scn15_10.mid\n",
      "Parsing Music/mendel_op19_6.mid\n",
      "Parsing Music/schub_d960_1.mid\n",
      "Parsing Music/chpn-p23.mid\n",
      "Parsing Music/chpn-p9.mid\n",
      "Parsing Music/burg_perlen.mid\n",
      "Parsing Music/scn16_8.mid\n",
      "Parsing Music/chpn-p8.mid\n",
      "Parsing Music/chpn-p22.mid\n",
      "Parsing Music/liz_rhap09.mid\n",
      "Parsing Music/schumm-6.mid\n",
      "Parsing Music/haydn_8_1.mid\n",
      "Parsing Music/scn15_11.mid\n",
      "Parsing Music/bach_846.mid\n",
      "Parsing Music/muss_5.mid\n",
      "Parsing Music/muss_7.mid\n",
      "Parsing Music/bach_850.mid\n",
      "Parsing Music/scn15_13.mid\n",
      "Parsing Music/haydn_8_3.mid\n",
      "Parsing Music/mendel_op19_5.mid\n",
      "Parsing Music/schumm-4.mid\n",
      "Parsing Music/chpn-p20.mid\n",
      "Parsing Music/schub_d960_2.mid\n",
      "Parsing Music/alb_se8.mid\n",
      "Parsing Music/gra_esp_2.mid\n",
      "Parsing Music/liz_et_trans8.mid\n",
      "Parsing Music/gra_esp_3.mid\n",
      "Parsing Music/grieg_halling.mid\n",
      "Parsing Music/schub_d960_3.mid\n",
      "Parsing Music/chpn-p21.mid\n",
      "Parsing Music/schumm-5.mid\n",
      "Parsing Music/mendel_op19_4.mid\n",
      "Parsing Music/haydn_8_2.mid\n",
      "Parsing Music/scn15_12.mid\n",
      "Parsing Music/scn68_12.mid\n",
      "Parsing Music/muss_6.mid\n",
      "Parsing Music/ty_november.mid\n",
      "Parsing Music/chp_op18.mid\n",
      "Parsing Music/chpn_op35_4.mid\n",
      "Parsing Music/mz_570_1.mid\n",
      "Parsing Music/rac_op23_5.mid\n",
      "Parsing Music/grieg_waechter.mid\n",
      "Error parsing file Music/chpn_op33_2.mid: 5390557392\n",
      "Parsing Music/chp_op31.mid\n",
      "Parsing Music/deb_prel.mid\n",
      "Parsing Music/fruehlingsrauschen.mid\n",
      "Parsing Music/ty_juni.mid\n",
      "Parsing Music/mz_570_2.mid\n",
      "Parsing Music/chpn_op25_e4.mid\n",
      "Parsing Music/rac_op3_2.mid\n",
      "Parsing Music/burg_erwachen.mid\n",
      "Parsing Music/rac_op23_7.mid\n",
      "Parsing Music/mz_570_3.mid\n",
      "Parsing Music/rav_ondi.mid\n",
      "Parsing Music/schuim-4.mid\n",
      "Parsing Music/mendel_op62_3.mid\n",
      "Parsing Music/ty_april.mid\n",
      "Error parsing file Music/chpn_op35_2.mid: 5883906272\n",
      "Parsing Music/scn15_8.mid\n",
      "Parsing Music/grieg_walzer.mid\n",
      "Parsing Music/beethoven_opus10_2.mid\n",
      "Parsing Music/rac_op23_3.mid\n",
      "Parsing Music/haydn_9_3.mid\n",
      "Parsing Music/chpn_op25_e1.mid\n",
      "Parsing Music/liz_donjuan.mid\n",
      "Parsing Music/grieg_butterfly.mid\n",
      "Parsing Music/chpn_op33_4.mid\n",
      "Parsing Music/chpn_op53.mid\n",
      "Parsing Music/hay_40_1.mid\n",
      "Parsing Music/haydn_9_2.mid\n",
      "Parsing Music/rac_op23_2.mid\n",
      "Parsing Music/beethoven_opus10_3.mid\n",
      "Parsing Music/ty_maerz.mid\n",
      "Parsing Music/elise.mid\n",
      "Parsing Music/scn15_9.mid\n",
      "Parsing Music/schuim-1.mid\n",
      "Parsing Music/chpn_op35_3.mid\n",
      "Parsing Music/ty_februar.mid\n",
      "Parsing Music/mendel_op62_4.mid\n",
      "Parsing Music/chpn_op35_1.mid\n",
      "Parsing Music/schuim-3.mid\n",
      "Parsing Music/beethoven_opus10_1.mid\n",
      "Parsing Music/chpn_op25_e2.mid\n",
      "Parsing Music/grieg_wanderer.mid\n",
      "Parsing Music/hay_40_2.mid\n",
      "Parsing Music/chpn_op25_e3.mid\n",
      "Parsing Music/haydn_9_1.mid\n",
      "Parsing Music/schuim-2.mid\n",
      "Parsing Music/mendel_op62_5.mid\n",
      "Parsing Music/appass_2.mid\n",
      "Parsing Music/clementi_opus36_3_1.mid\n",
      "Parsing Music/scn15_7.mid\n",
      "Parsing Music/grieg_album.mid\n",
      "Parsing Music/clementi_opus36_1_3.mid\n",
      "Parsing Music/brahms_opus1_4.mid\n",
      "Parsing Music/mendel_op53_5.mid\n",
      "Parsing Music/mz_545_1.mid\n",
      "Parsing Music/haydn_7_3.mid\n",
      "Parsing Music/mz_332_3.mid\n",
      "Parsing Music/burg_spinnerlied.mid\n",
      "Parsing Music/mz_330_1.mid\n",
      "Parsing Music/mz_332_2.mid\n",
      "Parsing Music/haydn_7_2.mid\n",
      "Parsing Music/grieg_voeglein.mid\n",
      "Parsing Music/grieg_spring.mid\n",
      "Parsing Music/chpn_op10_e12.mid\n",
      "Parsing Music/grieg_berceuse.mid\n",
      "Parsing Music/clementi_opus36_1_2.mid\n",
      "Parsing Music/scn15_6.mid\n",
      "Parsing Music/appass_3.mid\n",
      "Parsing Music/appass_1.mid\n",
      "Parsing Music/clementi_opus36_3_2.mid\n",
      "Parsing Music/rav_eau.mid\n",
      "Parsing Music/scn15_4.mid\n",
      "Parsing Music/schubert_D850_4.mid\n",
      "Parsing Music/ty_januar.mid\n",
      "Parsing Music/mendel_op30_5.mid\n",
      "Parsing Music/mz_545_2.mid\n",
      "Parsing Music/mz_330_2.mid\n",
      "Parsing Music/schubert_D935_4.mid\n",
      "Parsing Music/mz_330_3.mid\n",
      "Parsing Music/grieg_brooklet.mid\n",
      "Parsing Music/haydn_7_1.mid\n",
      "Parsing Music/mz_332_1.mid\n",
      "Parsing Music/mz_545_3.mid\n",
      "Parsing Music/mendel_op30_4.mid\n",
      "Parsing Music/chpn_op10_e05.mid\n",
      "Parsing Music/schub_d760_4.mid\n",
      "Parsing Music/clementi_opus36_1_1.mid\n",
      "Parsing Music/scn15_5.mid\n",
      "Parsing Music/ty_juli.mid\n",
      "Parsing Music/clementi_opus36_3_3.mid\n",
      "Parsing Music/grieg_once_upon_a_time.mid\n",
      "Parsing Music/mos_op36_6.mid\n",
      "Parsing Music/scn15_1.mid\n",
      "Parsing Music/beethoven_les_adieux_3.mid\n",
      "Parsing Music/schubert_D850_1.mid\n",
      "Parsing Music/chpn_op10_e01.mid\n",
      "Parsing Music/brahms_opus1_2.mid\n",
      "Parsing Music/clementi_opus36_5_1.mid\n",
      "Parsing Music/pathetique_1.mid\n",
      "Parsing Music/deb_clai_format0.mid\n",
      "Parsing Music/br_rhap.mid\n",
      "Parsing Music/schubert_D935_1.mid\n",
      "Parsing Music/chpn_op66.mid\n",
      "Error parsing file Music/brahms_opus1_3.mid: 5339896704\n",
      "Parsing Music/mendel_op30_1.mid\n",
      "Error parsing file Music/mendel_op30_1.mid: 'int' object has no attribute 'pitch'\n",
      "Parsing Music/mond_1.mid\n",
      "Parsing Music/schub_d760_1.mid\n",
      "Parsing Music/burg_geschwindigkeit.mid\n",
      "Parsing Music/beethoven_les_adieux_2.mid\n",
      "Parsing Music/ty_september.mid\n",
      "Parsing Music/liz_liebestraum.mid\n",
      "Parsing Music/grieg_march.mid\n",
      "Parsing Music/scn15_2.mid\n",
      "Parsing Music/schubert_D850_2.mid\n",
      "Error parsing file Music/schub_d760_3.mid: 5408101952\n",
      "Parsing Music/mond_3.mid\n",
      "Parsing Music/brahms_opus1_1.mid\n",
      "Parsing Music/mendel_op30_3.mid\n",
      "Parsing Music/pathetique_2.mid\n",
      "Parsing Music/clementi_opus36_5_2.mid\n",
      "Parsing Music/rac_op32_1.mid\n",
      "Parsing Music/schubert_D935_2.mid\n",
      "Error parsing file Music/schubert_D935_2.mid: 'int' object has no attribute 'pitch'\n",
      "Parsing Music/schubert_D935_3.mid\n",
      "Parsing Music/pathetique_3.mid\n",
      "Parsing Music/clementi_opus36_5_3.mid\n",
      "Parsing Music/mendel_op30_2.mid\n",
      "Parsing Music/mond_2.mid\n",
      "Parsing Music/schubert_D850_3.mid\n",
      "Parsing Music/schub_d760_2.mid\n",
      "Parsing Music/beethoven_les_adieux_1.mid\n",
      "Parsing Music/grieg_zwerge.mid\n",
      "Parsing Music/scn15_3.mid\n",
      "Parsing Music/burg_gewitter.mid\n",
      "Parsing Music/schu_143_2.mid\n",
      "Parsing Music/haydn_33_1.mid\n",
      "Parsing Music/mz_331_2.mid\n",
      "Parsing Music/bk_xmas4.mid\n",
      "Parsing Music/bor_ps1.mid\n",
      "Parsing Music/beethoven_opus22_1.mid\n",
      "Parsing Music/alb_esp3.mid\n",
      "Parsing Music/chpn-p10.mid\n",
      "Parsing Music/chpn_op25_e12.mid\n",
      "Parsing Music/alb_se4.mid\n",
      "Parsing Music/chpn-p6.mid\n",
      "Parsing Music/scn16_6.mid\n",
      "Parsing Music/rac_op32_13.mid\n",
      "Parsing Music/brahms_opus117_1.mid\n",
      "Parsing Music/clementi_opus36_2_2.mid\n",
      "Parsing Music/liz_et2.mid\n",
      "Parsing Music/ty_mai.mid\n",
      "Parsing Music/liz_et_trans5.mid\n",
      "Parsing Music/liz_et_trans4.mid\n",
      "Parsing Music/liz_et3.mid\n",
      "Parsing Music/clementi_opus36_2_3.mid\n",
      "Parsing Music/scn16_7.mid\n",
      "Parsing Music/chpn-p7.mid\n",
      "Parsing Music/alb_se5.mid\n",
      "Parsing Music/debussy_cc_6.mid\n",
      "Parsing Music/chpn-p11.mid\n",
      "Parsing Music/alb_esp2.mid\n",
      "Parsing Music/liz_rhap12.mid\n",
      "Parsing Music/mz_333_1.mid\n",
      "Parsing Music/bk_xmas5.mid\n",
      "Parsing Music/mz_331_3.mid\n",
      "Parsing Music/schu_143_3.mid\n",
      "Parsing Music/rac_op33_6.mid\n",
      "Parsing Music/muss_8.mid\n",
      "Parsing Music/schu_143_1.mid\n",
      "Error parsing file Music/schu_143_1.mid: 'int' object has no attribute 'pitch'\n",
      "Parsing Music/haydn_33_2.mid\n",
      "Parsing Music/ty_oktober.mid\n",
      "Parsing Music/mz_331_1.mid\n",
      "Parsing Music/bor_ps2.mid\n",
      "Parsing Music/grieg_wedding.mid\n",
      "Parsing Music/br_im5.mid\n",
      "Parsing Music/mz_333_3.mid\n",
      "Parsing Music/beethoven_opus22_2.mid\n",
      "Parsing Music/liz_rhap10.mid\n",
      "Parsing Music/chpn-p13.mid\n",
      "Parsing Music/debussy_cc_4.mid\n",
      "Parsing Music/chpn_op25_e11.mid\n",
      "Parsing Music/chpn-p5.mid\n",
      "Parsing Music/alb_se7.mid\n",
      "Parsing Music/burg_agitato.mid\n",
      "Parsing Music/scn16_5.mid\n",
      "Parsing Music/clementi_opus36_2_1.mid\n",
      "Parsing Music/brahms_opus117_2.mid\n",
      "Parsing Music/liz_et1.mid\n",
      "Parsing Music/rav_scarbo.mid\n",
      "Parsing Music/beethoven_hammerklavier_4.mid\n",
      "Parsing Music/god_alb_esp2.mid\n",
      "Parsing Music/scn16_4.mid\n",
      "Parsing Music/alb_se6.mid\n",
      "Parsing Music/chpn-p4.mid\n",
      "Parsing Music/deb_menu.mid\n",
      "Parsing Music/chpn-p12.mid\n",
      "Parsing Music/alb_esp1.mid\n",
      "Parsing Music/mz_333_2.mid\n",
      "Parsing Music/beethoven_opus22_3.mid\n",
      "Parsing Music/bor_ps3.mid\n",
      "Parsing Music/haydn_33_3.mid\n",
      "Parsing Music/rac_op33_5.mid\n",
      "Parsing Music/clementi_opus36_4_2.mid\n",
      "Parsing Music/bk_xmas2.mid\n",
      "Parsing Music/bor_ps7.mid\n",
      "Parsing Music/alb_esp5.mid\n",
      "Parsing Music/liz_rhap15.mid\n",
      "Parsing Music/ravel_miroirs_1.mid\n",
      "Parsing Music/debussy_cc_1.mid\n",
      "Parsing Music/chpn-p16.mid\n",
      "Parsing Music/alb_se2.mid\n",
      "Parsing Music/haydn_35_1.mid\n",
      "Parsing Music/liz_et4.mid\n",
      "Parsing Music/chpn_op27_2.mid\n",
      "Parsing Music/mz_311_1.mid\n",
      "Parsing Music/beethoven_hammerklavier_1.mid\n",
      "Parsing Music/liz_et5.mid\n",
      "Parsing Music/scn16_1.mid\n",
      "Parsing Music/alb_se3.mid\n",
      "Parsing Music/chpn-p1.mid\n",
      "Parsing Music/chpn-p17.mid\n",
      "Parsing Music/alb_esp4.mid\n",
      "Parsing Music/bor_ps6.mid\n",
      "Parsing Music/clementi_opus36_6_1.mid\n",
      "Parsing Music/bk_xmas3.mid\n",
      "Parsing Music/clementi_opus36_4_3.mid\n",
      "Parsing Music/clementi_opus36_4_1.mid\n",
      "Parsing Music/god_chpn_op10_e01.mid\n",
      "Parsing Music/bk_xmas1.mid\n",
      "Parsing Music/bor_ps4.mid\n",
      "Parsing Music/liz_rhap02.mid\n",
      "Parsing Music/alb_esp6.mid\n",
      "Parsing Music/beethoven_opus22_4.mid\n",
      "Parsing Music/debussy_cc_2.mid\n",
      "Parsing Music/chpn-p15.mid\n",
      "Parsing Music/alb_se1.mid\n",
      "Parsing Music/chpn-p3.mid\n",
      "Parsing Music/haydn_35_2.mid\n",
      "Parsing Music/scn16_3.mid\n",
      "Parsing Music/chpn_op27_1.mid\n",
      "Parsing Music/mz_311_2.mid\n",
      "Parsing Music/beethoven_hammerklavier_3.mid\n",
      "Parsing Music/liz_et6.mid\n",
      "Parsing Music/mz_311_3.mid\n",
      "Parsing Music/burg_trennung.mid\n",
      "Parsing Music/beethoven_hammerklavier_2.mid\n",
      "Parsing Music/scn16_2.mid\n",
      "Parsing Music/haydn_35_3.mid\n",
      "Parsing Music/chpn-p2.mid\n",
      "Parsing Music/grieg_elfentanz.mid\n",
      "Parsing Music/chpn-p14.mid\n",
      "Parsing Music/debussy_cc_3.mid\n",
      "Parsing Music/br_im2.mid\n",
      "Parsing Music/bor_ps5.mid\n",
      "Parsing Music/clementi_opus36_6_2.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6s/vk_yc2t1373g9gnbrdzy30g80000gn/T/ipykernel_6364/4018325961.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.notes = torch.tensor(notes, dtype=torch.float)\n",
      "/var/folders/6s/vk_yc2t1373g9gnbrdzy30g80000gn/T/ipykernel_6364/4018325961.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.durations = torch.tensor(durations, dtype=torch.float)\n",
      "/var/folders/6s/vk_yc2t1373g9gnbrdzy30g80000gn/T/ipykernel_6364/4018325961.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.offsets = torch.tensor(offsets, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"Music\"\n",
    "notes, durations, offsets = MusicLoader(folder_path).load_data()\n",
    "dataset = MIDIDataset(notes, durations, offsets)\n",
    "\n",
    "# Create data loader\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Discriminator Loss: 1.1302, Generator Loss: 0.7216\n",
      "Epoch [2/100], Discriminator Loss: 0.8088, Generator Loss: 0.7502\n",
      "Epoch [3/100], Discriminator Loss: 0.6353, Generator Loss: 0.7998\n",
      "Epoch [4/100], Discriminator Loss: 0.5619, Generator Loss: 0.8681\n",
      "Epoch [5/100], Discriminator Loss: 0.4948, Generator Loss: 0.9729\n",
      "Epoch [6/100], Discriminator Loss: 0.4041, Generator Loss: 1.1562\n",
      "Epoch [7/100], Discriminator Loss: 0.3036, Generator Loss: 1.4101\n",
      "Epoch [8/100], Discriminator Loss: 0.1882, Generator Loss: 1.9082\n",
      "Epoch [9/100], Discriminator Loss: 0.0814, Generator Loss: 2.6695\n",
      "Epoch [10/100], Discriminator Loss: 0.0502, Generator Loss: 3.2981\n",
      "Epoch [11/100], Discriminator Loss: 0.0402, Generator Loss: 3.3239\n",
      "Epoch [12/100], Discriminator Loss: 0.0261, Generator Loss: 3.8122\n",
      "Epoch [13/100], Discriminator Loss: 0.0214, Generator Loss: 3.8916\n",
      "Epoch [14/100], Discriminator Loss: 0.0192, Generator Loss: 4.0427\n",
      "Epoch [15/100], Discriminator Loss: 0.0154, Generator Loss: 4.1031\n",
      "Epoch [16/100], Discriminator Loss: 0.0167, Generator Loss: 4.0678\n",
      "Epoch [17/100], Discriminator Loss: 0.0226, Generator Loss: 4.1311\n",
      "Epoch [18/100], Discriminator Loss: 0.0413, Generator Loss: 3.6538\n",
      "Epoch [19/100], Discriminator Loss: 0.0493, Generator Loss: 3.9778\n",
      "Epoch [20/100], Discriminator Loss: 0.0175, Generator Loss: 4.7578\n",
      "Epoch [21/100], Discriminator Loss: 0.0038, Generator Loss: 5.9484\n",
      "Epoch [22/100], Discriminator Loss: 0.0010, Generator Loss: 7.1109\n",
      "Epoch [23/100], Discriminator Loss: 0.0006, Generator Loss: 7.6574\n",
      "Epoch [24/100], Discriminator Loss: 0.0006, Generator Loss: 7.5640\n",
      "Epoch [25/100], Discriminator Loss: 0.0008, Generator Loss: 7.1218\n",
      "Epoch [26/100], Discriminator Loss: 0.0019, Generator Loss: 6.3751\n",
      "Epoch [27/100], Discriminator Loss: 0.0033, Generator Loss: 5.7426\n",
      "Epoch [28/100], Discriminator Loss: 0.0044, Generator Loss: 5.7626\n",
      "Epoch [29/100], Discriminator Loss: 0.0018, Generator Loss: 6.6830\n",
      "Epoch [30/100], Discriminator Loss: 0.0004, Generator Loss: 8.1927\n",
      "Epoch [31/100], Discriminator Loss: 0.0001, Generator Loss: 9.2360\n",
      "Epoch [32/100], Discriminator Loss: 0.0001, Generator Loss: 9.6225\n",
      "Epoch [33/100], Discriminator Loss: 0.0001, Generator Loss: 9.6793\n",
      "Epoch [34/100], Discriminator Loss: 0.0001, Generator Loss: 9.3291\n",
      "Epoch [35/100], Discriminator Loss: 0.0002, Generator Loss: 9.0018\n",
      "Epoch [36/100], Discriminator Loss: 0.0002, Generator Loss: 8.7967\n",
      "Epoch [37/100], Discriminator Loss: 0.0002, Generator Loss: 8.6085\n",
      "Epoch [38/100], Discriminator Loss: 0.0002, Generator Loss: 8.4655\n",
      "Epoch [39/100], Discriminator Loss: 0.0003, Generator Loss: 8.3751\n",
      "Epoch [40/100], Discriminator Loss: 0.0003, Generator Loss: 8.3054\n",
      "Epoch [41/100], Discriminator Loss: 0.0003, Generator Loss: 8.2018\n",
      "Epoch [42/100], Discriminator Loss: 0.0003, Generator Loss: 8.1287\n",
      "Epoch [43/100], Discriminator Loss: 0.0003, Generator Loss: 8.0187\n",
      "Epoch [44/100], Discriminator Loss: 0.0004, Generator Loss: 7.9042\n",
      "Epoch [45/100], Discriminator Loss: 0.0005, Generator Loss: 7.6990\n",
      "Epoch [46/100], Discriminator Loss: 0.0007, Generator Loss: 7.3930\n",
      "Epoch [47/100], Discriminator Loss: 0.0013, Generator Loss: 6.8800\n",
      "Epoch [48/100], Discriminator Loss: 0.0053, Generator Loss: 5.9694\n",
      "Epoch [49/100], Discriminator Loss: 0.0061, Generator Loss: 5.6493\n",
      "Epoch [50/100], Discriminator Loss: 0.0045, Generator Loss: 7.4016\n",
      "Epoch [51/100], Discriminator Loss: 0.1320, Generator Loss: 6.3132\n",
      "Epoch [52/100], Discriminator Loss: 0.0005, Generator Loss: 8.2124\n",
      "Epoch [53/100], Discriminator Loss: 0.0029, Generator Loss: 7.0388\n",
      "Epoch [54/100], Discriminator Loss: 0.0016, Generator Loss: 9.6232\n",
      "Epoch [55/100], Discriminator Loss: 0.0082, Generator Loss: 10.4789\n",
      "Epoch [56/100], Discriminator Loss: 6.1439, Generator Loss: 1.0874\n",
      "Epoch [57/100], Discriminator Loss: 1.7538, Generator Loss: 1.1893\n",
      "Epoch [58/100], Discriminator Loss: 0.4615, Generator Loss: 4.8993\n",
      "Epoch [59/100], Discriminator Loss: 0.1005, Generator Loss: 5.6761\n",
      "Epoch [60/100], Discriminator Loss: 0.0618, Generator Loss: 5.4011\n",
      "Epoch [61/100], Discriminator Loss: 0.0347, Generator Loss: 4.3428\n",
      "Epoch [62/100], Discriminator Loss: 0.0897, Generator Loss: 4.1700\n",
      "Epoch [63/100], Discriminator Loss: 0.0406, Generator Loss: 4.9149\n",
      "Epoch [64/100], Discriminator Loss: 0.3618, Generator Loss: 3.8024\n",
      "Epoch [65/100], Discriminator Loss: 0.2946, Generator Loss: 3.3958\n",
      "Epoch [66/100], Discriminator Loss: 4.7275, Generator Loss: 0.1853\n",
      "Epoch [67/100], Discriminator Loss: 2.9629, Generator Loss: 0.1963\n",
      "Epoch [68/100], Discriminator Loss: 1.5328, Generator Loss: 0.6699\n",
      "Epoch [69/100], Discriminator Loss: 1.4000, Generator Loss: 0.7687\n",
      "Epoch [70/100], Discriminator Loss: 1.3714, Generator Loss: 0.7550\n",
      "Epoch [71/100], Discriminator Loss: 1.3633, Generator Loss: 0.7455\n",
      "Epoch [72/100], Discriminator Loss: 1.3513, Generator Loss: 0.7551\n",
      "Epoch [73/100], Discriminator Loss: 1.3336, Generator Loss: 0.7622\n",
      "Epoch [74/100], Discriminator Loss: 1.3038, Generator Loss: 0.7857\n",
      "Epoch [75/100], Discriminator Loss: 1.2618, Generator Loss: 0.8054\n",
      "Epoch [76/100], Discriminator Loss: 1.2061, Generator Loss: 0.8341\n",
      "Epoch [77/100], Discriminator Loss: 1.1291, Generator Loss: 0.8745\n",
      "Epoch [78/100], Discriminator Loss: 1.0390, Generator Loss: 0.9400\n",
      "Epoch [79/100], Discriminator Loss: 0.9314, Generator Loss: 1.0183\n",
      "Epoch [80/100], Discriminator Loss: 0.7908, Generator Loss: 1.1270\n",
      "Epoch [81/100], Discriminator Loss: 0.6635, Generator Loss: 1.2609\n",
      "Epoch [82/100], Discriminator Loss: 0.5413, Generator Loss: 1.4191\n",
      "Epoch [83/100], Discriminator Loss: 0.4425, Generator Loss: 1.5962\n",
      "Epoch [84/100], Discriminator Loss: 0.3643, Generator Loss: 1.7686\n",
      "Epoch [85/100], Discriminator Loss: 0.2938, Generator Loss: 1.9395\n",
      "Epoch [86/100], Discriminator Loss: 0.2445, Generator Loss: 2.1050\n",
      "Epoch [87/100], Discriminator Loss: 0.2075, Generator Loss: 2.2412\n",
      "Epoch [88/100], Discriminator Loss: 0.1777, Generator Loss: 2.3600\n",
      "Epoch [89/100], Discriminator Loss: 0.1632, Generator Loss: 2.4367\n",
      "Epoch [90/100], Discriminator Loss: 0.1635, Generator Loss: 2.4688\n",
      "Epoch [91/100], Discriminator Loss: 0.1830, Generator Loss: 2.3927\n",
      "Epoch [92/100], Discriminator Loss: 0.2599, Generator Loss: 2.1833\n",
      "Epoch [93/100], Discriminator Loss: 0.7287, Generator Loss: 1.3400\n",
      "Epoch [94/100], Discriminator Loss: 2.3241, Generator Loss: 0.9031\n",
      "Epoch [95/100], Discriminator Loss: 2.7082, Generator Loss: 0.7691\n",
      "Epoch [96/100], Discriminator Loss: 1.1928, Generator Loss: 1.0135\n",
      "Epoch [97/100], Discriminator Loss: 0.8956, Generator Loss: 1.5052\n",
      "Epoch [98/100], Discriminator Loss: 0.4646, Generator Loss: 2.0202\n",
      "Epoch [99/100], Discriminator Loss: 0.3191, Generator Loss: 2.1018\n",
      "Epoch [100/100], Discriminator Loss: 0.4181, Generator Loss: 2.2683\n"
     ]
    }
   ],
   "source": [
    "# Initialize Generator and Discriminator\n",
    "generator = LSTMGenerator(input_size=100, hidden_size=256, output_size=3, num_layers=2)  # Update output_size to 3\n",
    "discriminator = LSTMDiscriminator(input_size=3, hidden_size=256, num_layers=2)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 100\n",
    "lr_gen = 0.001\n",
    "lr_disc = 0.001\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Train the network\n",
    "best_gen_state, best_disc_state, gen_loss, disc_loss = train_network(generator, discriminator, train_loader, num_epochs, lr_gen, lr_disc, device)\n",
    "\n",
    "# Save the best performing model\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "# Save generator and discriminator with their loss values in the file names\n",
    "torch.save(best_gen_state, f'models/generator_loss_{gen_loss:.4f}.pth')\n",
    "torch.save(best_disc_state, f'models/discriminator_loss_{disc_loss:.4f}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
